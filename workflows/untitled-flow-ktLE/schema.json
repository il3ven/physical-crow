{
  "description": "",
  "env": {},
  "id": "QUSkIkH8znBtm5p8ktLE",
  "inputs": {
    "properties": {},
    "required": [],
    "type": "object"
  },
  "lastBranchDeploymentHash": {},
  "lastDeployment": 1751470564917,
  "lastDeploymentHash": "SRj/i0SFtOJ9vRiisIw0SNcaXKW7ENe/bct7RhvmM7c=",
  "name": "Untitled Flow",
  "nodeValues": {
    "792dcdc8-0cf5-4607-969b-591390951f86": {
      "_$bsCacheMaxAge_": 0,
      "_$bsStatusCode_": "200",
      "_$lastNodeOutput_": {
        "_$keys_": [
          "e8892a85-8d8d-4a4d-af81-437e717e9f42"
        ]
      }
    },
    "e19cce86-801e-46e9-ab4d-7908ad87e788": {
      "config.spreadsheetUrl": "https://docs.google.com/spreadsheets/d/1XFAUg5B-8-vODhTPxcF-DZrlnXQMpIwpGLuTIIwveLU",
      "oAuthIntegrations": {
        "gdrive": "gdrive;;bhavya@rowy.io"
      }
    },
    "e8892a85-8d8d-4a4d-af81-437e717e9f42": {
      "name": "Hello"
    }
  },
  "nodes": [
    {
      "id": "e8892a85-8d8d-4a4d-af81-437e717e9f42",
      "type": "script"
    },
    {
      "id": "792dcdc8-0cf5-4607-969b-591390951f86",
      "label": "Flow Output",
      "type": "output"
    }
  ],
  "outputs": {
    "properties": {
      "output": {
        "buildship": {
          "index": 0
        },
        "title": "Output"
      }
    },
    "required": [],
    "type": "object"
  },
  "runtimeVersion": "v3",
  "stickyNotes": {},
  "testExamples": {},
  "triggers": [
    {
      "_groupInfo": {
        "category": "Productivity",
        "description": "OAuth Nodes for utilizing the Google Sheets API to perform operations on your Google Sheets Document.",
        "iconUrl": "https://firebasestorage.googleapis.com/v0/b/website-a1s39m.appspot.com/o/buildship-app-logos%2FGoogleSheets.png?alt=media&token=89b3cfec-6746-43da-a404-5d20adb60472",
        "id": "0IAjU2tekQHjibkvicox",
        "longDescription": "OAuth Nodes for Google Sheets allow seamless integration with the Google Sheets API, enabling you to perform operations like reading, writing, and updating spreadsheets directly within your applications. Utilize this integration to create dynamic data-driven workflows, automate data manipulation tasks, and synchronize your sheets with other services effortlessly.",
        "name": "Google Sheets",
        "uid": "google-sheets"
      },
      "_libRef": {
        "integrity": "v3:b625ce699faa74dad35bc798c6de9d1c",
        "isDirty": false,
        "libNodeRefId": "@buildship/gsheet-trigger",
        "libType": "public",
        "src": "https://storage.googleapis.com/buildship-library-us-central1/triggers/@buildship/gsheet-trigger/3.0.0/__verify.cjs",
        "version": "3.0.0"
      },
      "config": {
        "properties": {
          "spreadsheetUrl": {
            "buildship": {
              "defaultExpressionType": "text",
              "index": 0,
              "sensitive": false
            },
            "default": "",
            "description": "The URL for your Google Sheet to link to.",
            "properties": {},
            "title": "Spreadsheet URL",
            "type": "string"
          }
        },
        "required": [
          "method",
          "table",
          "site_id",
          "triggerType",
          "spreadsheetUrl"
        ],
        "sections": {},
        "structure": [
          {
            "depth": 0,
            "id": "spreadsheetUrl",
            "index": 0,
            "parentId": null
          }
        ],
        "type": "object"
      },
      "data": {
        "buildship": {
          "index": 0
        },
        "properties": {
          "data": {
            "buildship": {
              "index": 0,
              "sensitive": true
            },
            "default": [],
            "items": {},
            "properties": {
              "cellNumber": {
                "buildship": {
                  "index": 2,
                  "sensitive": true
                },
                "default": "",
                "properties": {},
                "title": "cellNumber",
                "type": "string"
              },
              "newValue": {
                "buildship": {
                  "index": 0,
                  "sensitive": true
                },
                "default": "",
                "properties": {},
                "title": "newValue",
                "type": "string"
              },
              "previousValue": {
                "buildship": {
                  "index": 1,
                  "sensitive": true
                },
                "default": "",
                "properties": {},
                "title": "previousValue",
                "type": "string"
              }
            },
            "title": "data",
            "type": "array"
          },
          "request": {
            "buildship": {
              "index": 0
            },
            "properties": {
              "body": {
                "buildship": {
                  "index": 2
                },
                "title": "Body",
                "type": "string"
              },
              "headers": {
                "buildship": {
                  "index": 0
                },
                "properties": {},
                "title": "Headers",
                "type": "object"
              },
              "query": {
                "buildship": {
                  "index": 1
                },
                "properties": {},
                "title": "Query",
                "type": "object"
              }
            },
            "title": "Request",
            "type": "object"
          }
        },
        "title": "Data",
        "type": "object"
      },
      "dependencies": {
        "@google-cloud/scheduler": "5.1.0",
        "@google-cloud/storage": "7.15.2",
        "co-body": "6.1.0",
        "crypto": "1.0.1",
        "fs": "0.0.1-security",
        "google-auth-library": "9.15.1",
        "uuid": "11.1.0"
      },
      "description": "Triggers the workflow every time there's a change in your linked Google Sheet.",
      "id": "e19cce86-801e-46e9-ab4d-7908ad87e788",
      "integrations": [
        "gdrive"
      ],
      "label": "Google Sheet Trigger",
      "lastDeploymentHash": "U9mJsxs7QksI/DwwgtOJiyi0Xx28ltlPYwpHFr0ydog=",
      "lifeCycleFunctions": [
        "onCreate",
        "onUpdate",
        "onExecution",
        "onDelete",
        "getData"
      ],
      "meta": {
        "description": "Triggers the workflow every time there's a change in your linked Google Sheet.",
        "fileUploadLimit": false,
        "icon": {
          "type": "URL",
          "url": "https://firebasestorage.googleapis.com/v0/b/website-a1s39m.appspot.com/o/buildship-app-logos%2FGoogleSheets.png?alt=media&token=89b3cfec-6746-43da-a404-5d20adb60472"
        },
        "id": "gsheet-trigger",
        "name": "Google Sheet Trigger",
        "payloadLimit": false
      },
      "preSetupPreview": "<div\n  style={{\n    margin: \"22px\",\n    height: \"100%\",\n    display: \"flex\",\n    alignItems: \"center\",\n    justifyContent: \"center\",\n    flexDirection: \"column\",\n  }}\n>\n<div\n\tstyle={{\n\t\tdisplay: \"flex\",\n\t\talignItems: \"center\",\n\t\tjustifyContent: \"center\",\n\t\tflexDirection: \"column\",\n\t\tpadding: \"22px\",\n\t\twidth: \"100%\",\n        maxWidth: \"420px\"\n\t}}\n>\n\n\t<div\n\t\tstyle={{\n\t\t\tpadding: \"16px 16px\",\n\t\t\tbackgroundColor: props.theme.palette.elevation.sections,\n\t\t\tboxShadow: \"0px 4px 16px 0px rgba(0, 0, 0, 0.08)\",\n\t\t\tborderRadius: \"16px\",\n\t\t\twidth: \"100%\",\n\t\t}}\n\t>\n    <div\n      style={{\n        display: \"flex\",\n        padding: \"8px\",\n        backgroundColor: props.theme.palette.text[50],\n        borderRadius: \"8px\",\n        width: \"fit-content\"\n      }}\n  >\n    <img src=\"https://firebasestorage.googleapis.com/v0/b/website-a1s39m.appspot.com/o/buildship-app-logos%2FGoogleSheets.png?alt=media&token=89b3cfec-6746-43da-a404-5d20adb60472\" width=\"16\" height=\"16\" />\n  </div>\n\t\t<Typography sx={{ my: 2 }}>\n\t\t\tGoogle Sheet Trigger - Quick Set Up Guide\n\t\t</Typography>\n      <Typography sx={{ mb: -1.2 }}>{\"1. Sign into your Gmail Account\"}</Typography>\n\t\t<Typography\n\t\t\tsx={(theme) => ({\n\t\t\t\tcolor: theme.palette.text[400]\n\t\t\t})}\n\t\t>\n\t\t\tClick on the **Authenticate** button to log into your Google Drive Account.\n\t\t</Typography>\n\n      <Typography sx={{ mb: -1.2 }}>{\"2. Add the Sheet URL\"}</Typography>\n\t\t<Typography\n\t\t\tsx={(theme) => ({\n\t\t\t\tcolor: theme.palette.text[400]\n\t\t\t})}\n\t\t>\n\t\t\tCopy the URL to the Google Sheet you wish to link to this workflow.\n\t\t</Typography>\n\n      <Typography sx={{ mt: 2, mb: -1.2 }}>3. Click on the **Connect** button</Typography>\n\t\t<Typography\n\t\t\tsx={(theme) => ({\n\t\t\t\tcolor: theme.palette.text[400]\n\t\t\t})}\n\t\t>\n        And you're good to go! The workflow will be triggered each time there's a change in your Google Sheet content.\n\t\t</Typography>\n\n\n      <Typography sx={{ mt: 2, mb: -1.2 }}>NOTE:</Typography>\n\t\t<Typography\n\t\t\tsx={(theme) => ({\n\t\t\t\tcolor: theme.palette.text[400]\n\t\t\t})}\n\t\t>\n        Simply delete the trigger from your workflow to stop listening to the changes in your inbox.\n\t\t</Typography>\n\t</div>\n</div>\n</div>\n  ",
      "request": {
        "buildship": {},
        "description": "",
        "properties": {
          "body": {
            "buildship": {
              "index": 1
            },
            "description": "Body of the request",
            "properties": {
              "payload": {
                "buildship": {
                  "index": 0
                },
                "description": "",
                "title": "payload",
                "type": "string"
              },
              "triggerType": {
                "buildship": {
                  "index": 1
                },
                "description": "",
                "title": "triggerType",
                "type": "string"
              }
            },
            "title": "Body",
            "type": "object"
          },
          "headers": {
            "buildship": {
              "index": 0
            },
            "description": "Headers of the request",
            "title": "Request Headers",
            "type": "object"
          },
          "query": {
            "buildship": {
              "index": 2
            },
            "description": "Query parameters",
            "title": "Query",
            "type": "object"
          }
        },
        "required": [
          "body"
        ],
        "title": "Request",
        "type": "object"
      },
      "response": {
        "properties": {},
        "required": [],
        "type": "object"
      },
      "script": "import { CloudSchedulerClient } from \"@google-cloud/scheduler\";\nimport { Storage } from \"@google-cloud/storage\";\nimport { GoogleAuth } from \"google-auth-library\";\nimport { v4 as uuidv4 } from \"uuid\";\nimport { createHash } from \"crypto\";\nimport parser from \"co-body\";\nimport fs from \"fs/promises\";\n\n\nconst location = \"us-central1\";\nconst schedulerClient = new CloudSchedulerClient();\n\nconst locationIds = [\n  \"us-central1\", \"us-east1\", \"us-west1\", \"us-west2\", \"us-west3\", \"us-west4\",\n  \"europe-west1\", \"europe-west2\", \"europe-west3\", \"europe-west6\",\n  \"asia-east1\", \"asia-northeast1\", \"asia-south1\", \"asia-southeast1\"\n];\n\n// Google Drive Watch Request Functions\n\nasync function sendWatchRequest({ access_token, fileId, workflowId, triggerId, runtimeUrl, env }) {\n  try {\n    const url = new URL(`https://www.googleapis.com/drive/v2/files/${fileId}/watch`);\n    url.searchParams.append(\"supportsAllDrives\", \"true\");\n\n    const uniqueChannelId = `${workflowId}-${triggerId}`;\n    const webhookEndpointUrl = `${runtimeUrl}/executeWorkflow/${workflowId}/${triggerId}`;\n    const ttl = 86400;\n\n    const body = {\n      id: uniqueChannelId,\n      type: \"web_hook\",\n      address: webhookEndpointUrl,\n      params: {\n        ttl: ttl,\n      },\n    };\n\n    const response = await fetch(url.toString(), {\n      method: \"POST\",\n      headers: {\n        Authorization: `Bearer ${access_token}`,\n        \"Content-Type\": \"application/json\",\n      },\n      body: JSON.stringify(body),\n    });\n\n    if (response.status === 400) {\n      console.log(\"Bad request:\", await response.text());\n      return {\n        success: true,\n        message: \"Trigger deployed, channel already exists\",\n        ttl: ttl,\n      };\n    }\n\n    const responseJson = await response.json();\n    console.log(\"watch resp\", responseJson);\n\n    await env.set({\n      name: \"resourceId\",\n      value: responseJson.resourceId,\n    });\n\n    return {\n      ...responseJson,\n      ttl: ttl,\n    };\n  } catch (error) {\n    console.error(\"Error subscribing to file changes:\", error);\n    throw error;\n  }\n}\n\n\n// Cloud Scheduler Functions\n\nconst getHttpTarget = (runtimeUrl, workflowId, triggerId) => ({\n  uri: `${runtimeUrl}/executeWorkflow/${workflowId}/${triggerId}`,\n  httpMethod: \"POST\",\n  headers: {\n    \"Content-Type\": \"application/json\",\n    \"X-Cloud-Scheduler-Rewatch\": \"true\",\n  },\n  // Using OIDC token for authentication instead of basic auth\n  oidcToken: {\n    serviceAccountEmail: `runtime@${process.env.GCLOUD_PROJECT}.iam.gserviceaccount.com`,\n    audience: `${process.env.GCLOUD_PROJECT}/${triggerId}`,\n  },\n});\n\n\nasync function createOrUpdateSchedulerJob({ workflowId, triggerId, runtimeUrl, logging }) {\n  try {\n    const projectId = process.env.GCLOUD_PROJECT;\n    const schedule = \"0 0,12 * * *\"; // Runs at 12:00 AM and 12:00 PM every day\n    const timeZone = \"UTC\";\n    logging?.log(`Using project ID: ${projectId}`);\n\n    let locationId = process.env.SERVICE_REGION || location;\n    locationId = locationIds.includes(locationId) ? locationId : \"us-central1\";\n    \n    const parent = `projects/${projectId}/locations/${locationId}`;\n    const jobName = `bs-gdrive-rewatch-${workflowId}-${triggerId}`;\n    const fullJobName = `${parent}/jobs/${jobName}`;\n\n    const httpTarget = getHttpTarget(runtimeUrl, workflowId, triggerId);\n\n    try {\n      // Try to create the job first\n      const response = await schedulerClient.createJob({\n        parent,\n        job: {\n          name: fullJobName,\n          schedule,\n          timeZone,\n          httpTarget,\n        },\n      });\n\n      logging?.log(`Created scheduler job: ${response[0].name}`);\n      return {\n        success: true,\n        job: response[0],\n        message: \"Scheduler job created successfully\",\n      };\n    } catch (createError) {\n      if (createError.code === 6) {\n        logging?.log(`Job ${jobName} already exists, updating...`);\n\n        try {\n          // Update the existing job\n          const response = await schedulerClient.updateJob({\n            job: {\n              name: fullJobName,\n              schedule,\n              timeZone,\n              httpTarget,\n            },\n          });\n\n          logging?.log(`Updated scheduler job: ${response[0].name}`);\n          return {\n            success: true,\n            job: response[0],\n            message: \"Scheduler job updated successfully\",\n          };\n        } catch (updateError) {\n          logging?.log(`Failed to update job ${jobName}: ${updateError.message}`);\n          throw updateError;\n        }\n      } else {\n        throw createError;\n      }\n    }\n  } catch (error) {\n    console.error(\"Error creating/updating scheduler job:\", error);\n    logging?.log(`Error in scheduler job creation: ${error.message}`);\n    throw error;\n  }\n}\n\nasync function deleteSchedulerJob({ workflowId, triggerId, logging }) {\n  try {\n    const projectId = process.env.GCLOUD_PROJECT;\n\n    let locationId = process.env.SERVICE_REGION || location;\n    locationId = locationIds.includes(locationId) ? locationId : \"us-central1\";\n    \n    const parent = `projects/${projectId}/locations/${locationId}`;\n    const jobName = `bs-gdrive-rewatch-${workflowId}-${triggerId}`;\n    const fullJobName = `${parent}/jobs/${jobName}`;\n\n    try {\n      await schedulerClient.deleteJob({\n        name: fullJobName,\n      });\n\n      logging?.log(`Deleted scheduler job: ${jobName}`);\n      return {\n        success: true,\n        deletedJob: jobName,\n        message: \"Scheduler job deleted successfully\",\n      };\n    } catch (deleteError) {\n      if (deleteError.code === 5) { // NOT_FOUND error code\n        logging?.log(`Job ${jobName} not found (already deleted)`);\n        return {\n          success: true,\n          deletedJob: null,\n          message: \"Job was already deleted or did not exist\",\n        };\n      } else {\n        logging?.log(`Failed to delete job ${jobName}: ${deleteError.message}`);\n        throw deleteError;\n      }\n    }\n  } catch (error) {\n    console.error(\"Error deleting scheduler job:\", error);\n    logging?.log(`Error in scheduler job deletion: ${error.message}`);\n    throw error;\n  }\n}\n\n\n// Storage Functions\n\nasync function folderExists(bucket, folderPath) {\n  const [exists] = await bucket.file(folderPath + \"/\").exists();\n  return exists;\n}\n\nasync function createFolders(bucket, folders) {\n  let currentPath = \"\";\n  for (const folder of folders) {\n    currentPath += folder + \"/\";\n    const exists = await folderExists(bucket, currentPath);\n    if (!exists) {\n      const file = bucket.file(currentPath);\n      try {\n        await file.save(\"\");\n        console.log(`Folder \"${currentPath}\" created successfully.`);\n      } catch (error) {\n        console.error(`Error creating folder \"${currentPath}\":`, error);\n        throw error;\n      }\n    }\n  }\n}\n\nasync function uploadTextGCPStorage({ text, fileName }) {\n  const folders = fileName.split(\"/\").slice(0, -1);\n  const storage = new Storage();\n  const bucket = storage.bucket(process.env.BUCKET);\n  const file = bucket.file(fileName);\n\n  try {\n    if (folders.length > 0) {\n      await createFolders(bucket, folders);\n    }\n\n    await file.save(text);\n    await file.makePublic();\n\n    return {\n      status: \"success\",\n      message: \"Text uploaded successfully\",\n      url: `https://storage.googleapis.com/${process.env.BUCKET}/${fileName}`,\n    };\n  } catch (error) {\n    console.error(\"Error uploading text to GCP Storage:\", error);\n    throw error;\n  }\n}\n\nasync function getFileFromStorage({ filePath, logging }) {\n  const bucketFilePath = process.env.BUCKET_FOLDER_PATH + \"/\" + filePath;\n\n  try {\n    const contents = await fs.readFile(bucketFilePath, \"utf-8\");\n    return contents;\n  } catch (error) {\n    logging.log(error);\n    throw error;\n  }\n}\n\n\n// File Content Functions\n\nasync function getFileContents({ fileId, access_token, logging }) {\n  try {\n    // Fetch file metadata and download URL\n    const metadataUrl = new URL(`https://www.googleapis.com/drive/v3/files/${fileId}`);\n    metadataUrl.searchParams.append(\"fields\", \"version,modifiedTime,mimeType,exportLinks\");\n\n    const metadataResponse = await fetch(metadataUrl.toString(), {\n      method: \"GET\",\n      headers: {\n        Authorization: `Bearer ${access_token}`,\n        \"Content-Type\": \"application/json\",\n      },\n    });\n\n    if (!metadataResponse.ok) {\n      const errorText = await metadataResponse.text();\n      logging.log(\"Failed to fetch file metadata:\", errorText);\n      throw new Error(`Failed to fetch file metadata: ${errorText}`);\n    }\n\n    const { version, modifiedTime, mimeType } = await metadataResponse.json();\n\n    // Fetch file contents\n    const contentUrl = `https://www.googleapis.com/drive/v3/files/${fileId}/export`;\n    const exportParams = new URLSearchParams({\n      mimeType:\n        mimeType === \"application/vnd.google-apps.document\"\n          ? \"text/plain\"\n          : mimeType === \"application/vnd.google-apps.spreadsheet\"\n            ? \"text/csv\"\n            : mimeType,\n    });\n\n    const contentResponse = await fetch(`${contentUrl}?${exportParams}`, {\n      method: \"GET\",\n      headers: {\n        Authorization: `Bearer ${access_token}`,\n      },\n    });\n\n    if (!contentResponse.ok) {\n      const errorText = await contentResponse.text();\n      logging.log(\"Failed to fetch file contents:\", errorText);\n      throw new Error(`Failed to fetch file contents: ${errorText}`);\n    }\n\n    const fileContents = await contentResponse.text();\n    logging.log(\"File Version:\", version, \"Modified Time:\", modifiedTime);\n\n    return {\n      version,\n      modifiedTime,\n      mimeType,\n      contents: fileContents,\n    };\n  } catch (e) {\n    logging.log(\"Error in file fetch:\", e.message);\n    throw new Error(e.message);\n  }\n}\n\nasync function sha256FileComparison({ csvContent1, csvContent2, logging }) {\n  const content1 =\n    typeof csvContent1 === \"object\" && csvContent1.contents ? csvContent1.contents : csvContent1;\n  const content2 =\n    typeof csvContent2 === \"object\" && csvContent2.contents ? csvContent2.contents : csvContent2;\n\n  if (!content1 || !content2) {\n    logging.log(\"One or both CSV contents are empty.\");\n    return false;\n  }\n\n  try {\n    const buffer1 = Buffer.from(content1, \"utf-8\");\n    const buffer2 = Buffer.from(content2, \"utf-8\");\n\n    const hash1 = createHash(\"sha256\").update(buffer1).digest(\"hex\");\n    const hash2 = createHash(\"sha256\").update(buffer2).digest(\"hex\");\n\n    return hash1 !== hash2;\n  } catch (error) {\n    console.error(\"Error comparing files:\", error);\n    throw error;\n  }\n}\n\nasync function getCSVChanges({ newCSV, prevCSV, logging }) {\n  const changes = [];\n\n  const parseCSV = (csv) => {\n    if (!csv || !csv.trim()) return [];\n    return csv\n      .trim()\n      .split(/\\r?\\n/)\n      .map((line) => line.split(\",\").map((cell) => cell.trim()));\n  };\n\n  const prevData = parseCSV(prevCSV);\n  const newData = parseCSV(newCSV);\n\n  const getColumnLetter = (index) => {\n    let letter = \"\";\n    index = index + 1;\n\n    while (index > 0) {\n      const remainder = (index - 1) % 26;\n      letter = String.fromCharCode(97 + remainder) + letter;\n      index = Math.floor((index - 1) / 26);\n    }\n\n    return letter;\n  };\n\n  const getCellRef = (row, col) => {\n    return `${getColumnLetter(col)}${row + 1}`;\n  };\n\n  const maxRows = Math.max(prevData.length, newData.length);\n\n  for (let row = 0; row < maxRows; row++) {\n    const prevRow = prevData[row] || [];\n    const newRow = newData[row] || [];\n    const maxCols = Math.max(prevRow.length, newRow.length);\n\n    for (let col = 0; col < maxCols; col++) {\n      const prevValue =\n        row < prevData.length && col < prevData[row].length ? prevData[row][col] : \"\";\n      const newValue = row < newData.length && col < newData[row].length ? newData[row][col] : \"\";\n\n      if (prevValue !== newValue) {\n        changes.push({\n          cellNumber: getCellRef(row, col),\n          previousValue: prevValue,\n          newValue: newValue,\n        });\n      }\n    }\n  }\n\n  return changes;\n}\n\n\n// Auth and Logging Functions\n\nconst getAccessToken = async () => {\n  const response = await fetch(\n    \"http://metadata/computeMetadata/v1/instance/service-accounts/default/token\",\n    {\n      headers: { \"Metadata-Flavor\": \"Google\" },\n    },\n  );\n\n  if (!response.ok) {\n    throw new Error(`Failed to obtain access token: ${response.statusText}`);\n  }\n\n  const data = await response.json();\n  return data.access_token;\n};\n\nconst fetchLogEntries = async (triggerId, retries = 3, delay = 1000) => {\n  const projectId = process.env.GCLOUD_PROJECT;\n\n  try {\n    const accessToken = await getAccessToken();\n    const filter = `logName=\"projects/${projectId}/logs/buildship-node-io\" AND jsonPayload.nId=\"${triggerId}\"`;\n\n    const requestBody = {\n      resourceNames: [`projects/${projectId}`],\n      filter: filter,\n      pageSize: 1,\n      orderBy: \"timestamp desc\",\n    };\n\n    for (let attempt = 1; attempt <= retries; attempt++) {\n      try {\n        const response = await fetch(\"https://logging.googleapis.com/v2/entries:list\", {\n          method: \"POST\",\n          headers: {\n            Authorization: `Bearer ${accessToken}`,\n            \"Content-Type\": \"application/json\",\n          },\n          body: JSON.stringify(requestBody),\n        });\n\n        if (!response.ok) {\n          const errorText = await response.text();\n          throw new Error(\n            `Error fetching log entries: ${response.status} ${response.statusText} - ${errorText}`,\n          );\n        }\n\n        const data = await response.json();\n        const entries = data.entries || [];\n\n        if (entries.length > 0) {\n          return entries;\n        }\n\n        if (attempt < retries) {\n          await new Promise((resolve) => setTimeout(resolve, delay));\n        }\n      } catch (error) {\n        console.error(`Attempt ${attempt} failed due to an error:`, error);\n        if (attempt < retries) {\n          await new Promise((resolve) => setTimeout(resolve, delay));\n        } else {\n          throw error;\n        }\n      }\n    }\n\n    throw new Error(\"No data found. Send a request to the API and try again.\");\n  } catch (error) {\n    console.error(\"Error in fetchLogEntries:\", error);\n    throw error;\n  }\n};\n\n\n// Main Handler Functions\n\nasync function onCreate({ spreadsheetUrl }, { auth, workflow, trigger, runtimeUrl, env }) {\n  const fileId = spreadsheetUrl.match(/[-\\w]{25,}/)[0];\n  const { access_token } = await auth.getToken();\n\n  const resp = await sendWatchRequest({\n    access_token,\n    workflowId: workflow.id,\n    triggerId: trigger.id,\n    fileId: fileId,\n    runtimeUrl: runtimeUrl,\n    env,\n  });\n\n  console.log(\"watch resp\", resp);\n\n  const schedulerSetup = await createOrUpdateSchedulerJob({\n    workflowId: workflow.id,\n    triggerId: trigger.id,\n    runtimeUrl: runtimeUrl,\n    logging: console,\n  });\n\n  console.log(\"schedulerSetup\", schedulerSetup);\n\n  const { contents } = await getFileContents({\n    fileId,\n    access_token,\n    logging: console,\n  });\n\n  console.log(\"contents\", contents);\n\n  const fileName = `${trigger.id}/${fileId}.csv`;\n  const uploadResponse = await uploadTextGCPStorage({\n    text: contents,\n    fileName,\n  });\n\n  console.log(\"upload contents\", uploadResponse);\n\n  if (uploadResponse.status !== \"success\") {\n    throw new Error(\"Failed to upload file contents to GCP Storage\");\n  }\n\n  return {\n    success: true,\n    message: \"Subscription created successfully\",\n    data: resp,\n    scheduler: schedulerSetup,\n  };\n}\n\nasync function onExecution(\n  { spreadsheetUrl },\n  { nodeReq, logging, request, trigger, auth, workflow, runtimeUrl, env, terminate },\n) {\n  try {\n    const body = request.body ?? (await parser[\"json\"](nodeReq));\n    const isRewatchRequest =\n      request.headers[\"x-cloud-scheduler-rewatch\"] === \"true\" ||\n      body?.source === \"cloud-scheduler-rewatch\";\n\n    if (isRewatchRequest) {\n      logging.log(\"Processing rewatch request from Cloud Scheduler\");\n\n      const fileId = spreadsheetUrl.match(/[-\\w]{25,}/)[0];\n      const { access_token } = await auth.getToken();\n\n      const rewatchResp = await sendWatchRequest({\n        access_token,\n        workflowId: workflow.id,\n        triggerId: trigger.id,\n        fileId: fileId,\n        runtimeUrl: runtimeUrl,\n        env,\n      });\n\n      logging.log(\"Rewatch completed successfully\");\n      return terminate(202, \"watch request renewed\")\n    }\n\n    const ret = {\n      query: request.query,\n      headers: request.headers,\n      body: body !== null && body !== void 0 ? body : {},\n    };\n\n    logging.log(ret);\n\n    const resourceUri = request.headers[\"x-goog-resource-uri\"];\n    const fileId = resourceUri.match(/\\/files\\/([^\\/]+)\\?/)[1];\n    logging.log(\"fileId\", fileId);\n    const { access_token } = await auth.getToken();\n\n    const { contents } = await getFileContents({\n      fileId,\n      access_token,\n      logging,\n    });\n\n    logging.log(\"fresh content\", contents);\n\n    const oldContents = await getFileFromStorage({\n      filePath: `${trigger.id}/${fileId}.csv`,\n      logging,\n    });\n\n    const isDifferent = await sha256FileComparison({\n      csvContent1: contents,\n      csvContent2: oldContents,\n      logging,\n    });\n\n    if (!isDifferent) {\n      logging.log(\"File contents are the same, no action taken.\");\n      return \"No changes detected.\";\n    }\n\n    const changes = await getCSVChanges({\n      newCSV: contents,\n      prevCSV: oldContents,\n      logging,\n    });\n    logging.log(\"CSV Changes:\", changes);\n\n    const fileName = `${trigger.id}/${fileId}.csv`;\n    const uploadResponse = await uploadTextGCPStorage({\n      text: contents,\n      fileName,\n    });\n\n    if (uploadResponse.status !== \"success\") {\n      throw new Error(\"Failed to upload file contents to GCP Storage\");\n    }\n\n    return {\n      data: changes,\n      request: ret,\n    };\n  } catch (e) {\n    logging.error(e);\n    throw e;\n  }\n}\n\nasync function onDelete({}, { env, auth, workflow, trigger }) {\n  try {\n    const { access_token } = await auth.getToken();\n    const url = \"https://www.googleapis.com/drive/v3/channels/stop\";\n    const channelId = `${workflow.id}-${trigger.id}`;\n    const resourceId = env.get(\"resourceId\");\n\n    if (!resourceId) {\n      throw new Error(\"resourceId not found in env\");\n    }\n\n    const body = {\n      id: channelId,\n      resourceId: resourceId,\n    };\n\n    const response = await fetch(url, {\n      method: \"POST\",\n      headers: {\n        Authorization: `Bearer ${access_token}`,\n        \"Content-Type\": \"application/json\",\n      },\n      body: JSON.stringify(body),\n    });\n\n    if (!response.ok) {\n      const errorText = await response.text();\n      throw new Error(`HTTP error! status: ${response.status}, message: ${errorText}`);\n    }\n\n    const schedulerCleanup = await deleteSchedulerJob({\n      workflowId: workflow.id,\n      triggerId: trigger.id,\n      logging: console,\n    });\n\n    console.log(\"Scheduler cleanup:\", schedulerCleanup);\n\n    return {\n      success: true,\n      message: \"Channel successfully stopped\",\n      scheduler: schedulerCleanup,\n    };\n  } catch (error) {\n    console.error(\"Error stopping notification channel:\", error);\n    throw error;\n  }\n}\n\nconst getData = async (inputs, { trigger, workflow }) => {\n  try {\n    const entries = await fetchLogEntries(trigger.id, 5, 2000);\n    if (!entries || entries.length === 0) {\n      return { success: false, message: \"No entries found\", data: null };\n    }\n    return {\n      success: true,\n      message: \"\",\n      data: entries[0].jsonPayload?.o || null,\n    };\n  } catch (err) {\n    console.error(\"Error in getData:\", err);\n    return {\n      success: false,\n      message: err?.message || \"Unknown error\",\n      data: null,\n    };\n  }\n};\n\nexport default {\n  onCreate,\n  onUpdate: onCreate,\n  onExecution,\n  onDelete,\n  getData,\n};",
      "setupPreview": "<div\n  style={{\n    display: \"flex\",\n    // height: \"700px\",\n    // overflowY: \"auto\",\n    alignItems: \"center\",\n    justifyContent: \"center\",\n    flexDirection: \"column\",\n    // margin: \"22px\",\n    padding: \"22px\",\n  }}\n>\n  <div\n    style={{\n      padding: \"24px\",\n      backgroundColor: props.theme.palette.elevation.sections,\n      boxShadow: \"0px 4px 16px 0px rgba(0, 0, 0, 0.08)\",\n      borderRadius: \"16px\",\n      width: \"100%\"\n    }}\n  >\n    <Typography sx={{ marginBottom: \"8px\" }}>{\"Your trigger is ready to receive data!\"}</Typography>\n    <Typography sx={(theme) => ({ color: theme.palette.text[400], marginBottom: \"24px\" })}>\n      Make a change to your linked Google Sheet and use the received data to define your workflow input schema.\n    </Typography>\n    <Typography sx={{ marginBottom: \"8px\" }}>{\"1. Make a change to your Google Sheet\"}</Typography>\n    <Typography sx={(theme) => ({ color: theme.palette.text[400], marginBottom: \"24px\" })}>\n      Any change made to your Google Sheet content would trigger the workflow.\n    </Typography>\n    <InputsBinder\n      header=\"2. Get the latest request\"\n      description=\"\"\n      trigger={props.trigger}\n      resultHeader=\"3. Select the paths to update your input schema\"\n      resultDescription=\"No data received yet!\"\n    />\n  </div>\n</div>\n",
      "type": "webhook",
      "usage": ""
    }
  ],
  "variables": {
    "_$bsCacheMaxAge_": {
      "buildship": {
        "index": 0
      },
      "default": 0,
      "title": "Flow Output Cache Time",
      "type": "number"
    },
    "_$bsStatusCode_": {
      "buildship": {
        "index": 0
      },
      "title": "Flow Output Status Code",
      "type": "string"
    }
  },
  "versionId": "clgOZwhI6QehqG0pfFD6B7fyJllxXRSerX_tG6CoCxk"
}